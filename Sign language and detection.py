# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SQ8JAlPVP_7e6PafBqxrpDhh_hh4TtDi
"""

from google.colab import drive
drive.mount('/content/drive')

!cp "/content/drive/MyDrive/Colab Notebooks/dataset.zip" /content/

!unzip -q dataset.zip -d asl_dataset

!ls

!ls asl_dataset.h5

import os
import numpy as np
import cv2
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

data_dir = 'asl_dataset/asl_alphabet_train/asl_alphabet_train'
categories = sorted(os.listdir(data_dir))
label_map = {category: idx for idx, category in enumerate(categories)}

data = []
labels = []

# Loop over each category
for category in categories:
    path = os.path.join(data_dir, category)
    for img_name in os.listdir(path)[:300]:  # Limit images per class for speed
        img_path = os.path.join(path, img_name)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (64, 64))  # Resize images to 64x64 pixels
        data.append(img)
        labels.append(label_map[category])

X = np.array(data) / 255.0  # Normalize images
y = to_categorical(labels, num_classes=len(categories))  # One-hot encode labels

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)  # Split into train and validation sets

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(len(categories), activation='softmax')  # Output layer for each category
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))

model.save('asl_model.h5')  # Save the trained model

!pip install opencv-python-headless

from IPython.display import display, Javascript
from google.colab.output import eval_js
from google.colab.patches import cv2_imshow
import cv2
import numpy as np
import PIL
from PIL import Image
import io
import base64

def take_photo(filename='photo.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'ðŸ“¸ Take a photo';
      div.appendChild(capture);
      document.body.appendChild(div);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);

      stream.getTracks().forEach(track => track.stop());
      video.remove();
      capture.remove();

      const dataUrl = canvas.toDataURL('image/jpeg', quality);
      return dataUrl;
    }
  ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = base64.b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)

  return filename

from IPython.display import Image as ColabImage
image_path = take_photo()
ColabImage(image_path)

from tensorflow.keras.preprocessing import image
import numpy as np

# Load the captured image
img_path = 'photo.jpg'  # The path to the saved image
img = image.load_img(img_path, target_size=(224, 224))  # Resize the image to the required size

# Convert the image to a numpy array and normalize
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension to match the model input

# Normalize the image (if required by your model)
img_array = img_array / 255.0  # Assuming the model was trained on images normalized to [0, 1]

# You can now use this `img_array` to make predictions with your model



from tensorflow.keras.preprocessing import image
import numpy as np

def preprocess_image(image_path):
    # Load the image with target size of (224, 224)
    img = image.load_img(image_path, target_size=(224, 224))

    # Convert the image to a numpy array
    img_array = image.img_to_array(img)

    # Add an extra dimension to match the batch size (1, 224, 224, 3)
    img_array = np.expand_dims(img_array, axis=0)

    # Normalize the image (values between 0 and 1)
    img_array = img_array / 255.0

    return img_array

from IPython.display import display, Javascript
from google.colab.output import eval_js
import numpy as np
import cv2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model
import base64
import io
from PIL import Image

# Load your pre-trained model (adjust the path as needed)
model = load_model('/content/drive/MyDrive/Colab Notebooks/asl_model.h5')

# Function to capture image from webcam
def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const capture = document.createElement('button');
            capture.textContent = 'ðŸ“¸ Take a photo';
            div.appendChild(capture);
            document.body.appendChild(div);

            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});

            document.body.appendChild(video);
            video.srcObject = stream;
            await video.play();

            // Resize
            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

            await new Promise((resolve) => capture.onclick = resolve);

            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);

            stream.getTracks().forEach(track => track.stop());
            video.remove();
            capture.remove();

            const dataUrl = canvas.toDataURL('image/jpeg', quality);
            return dataUrl;
        }
    ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = base64.b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)

    return filename

# Function to preprocess the image to match the expected input shape
def preprocess_image(image_path):
    img = image.load_img(image_path, target_size=(64, 64))
    img_array = image.img_to_array(img) / 255.0
    return np.expand_dims(img_array, axis=0)


# Function to make predictions
def predict_image():
    # Capture an image from the webcam
    image_path = take_photo()

    # Preprocess the captured image
    img_array = preprocess_image(image_path)

    # Make a prediction
    pred = model.predict(img_array)

    # Print or interpret the result
    print(f"Prediction result: {pred}")

# Run the prediction function
predict_image()

import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model

# Load your trained model
model = load_model('asl_model.h5')

# Ensure class labels are defined (update these as per your dataset)
class_labels = [
    "A", "B", "C", "D", "E", "F", "G", "H", "I", "J",
    "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T",
    "U", "V", "W", "X", "Y", "Z"
]

# Function to preprocess the captured image
def preprocess_image(image_path, target_size=(64, 64)):
    """
    Preprocess the image for model prediction.
    - Resize to the target size.
    - Normalize pixel values.
    """
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB
    img = cv2.resize(img, target_size)  # Resize to match model input
    img = img / 255.0  # Normalize pixel values
    img_array = np.expand_dims(img, axis=0)  # Add batch dimension
    return img_array

# Function to capture an image using the webcam
def capture_image_from_webcam(output_path='captured_image.jpg'):
    """
    Capture an image from the webcam and save it.
    """
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        raise RuntimeError("Could not access the webcam.")

    print("Press 'Space' to capture the image or 'Q' to quit.")
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Failed to capture image. Try again.")
            continue

        cv2.imshow("Capture Image", frame)
        key = cv2.waitKey(1)

        if key == ord(' '):  # Space key to capture
            cv2.imwrite(output_path, frame)
            print(f"Image saved to {output_path}.")
            break
        elif key == ord('q'):  # 'Q' to quit
            print("Exiting without saving.")
            break

    cap.release()
    cv2.destroyAllWindows()
    return output_path

# Function to predict the class of the captured image
def predict_image():
    """
    Capture an image, preprocess it, and predict its class using the trained model.
    """
    try:
        image_path = capture_image_from_webcam()
        img_array = preprocess_image(image_path)

        pred = model.predict(img_array)
        predicted_class = np.argmax(pred)
        predicted_label = class_labels[predicted_class]

        print("Prediction Confidence:", pred)
        print("Predicted Class:", predicted_label)
    except Exception as e:
        print("Error during prediction:", str(e))

# Run the prediction function
predict_image()

from IPython.display import display, Javascript
from google.colab.output import eval_js
from google.colab.patches import cv2_imshow
import cv2
import numpy as np
import PIL.Image
import io

def capture_image():
    js = Javascript('''
        async function takePhoto() {
          const div = document.createElement('div');
          const capture = document.createElement('button');
          capture.textContent = 'Capture';
          div.appendChild(capture);

          const video = document.createElement('video');
          video.style.display = 'block';
          const stream = await navigator.mediaDevices.getUserMedia({video: true});

          document.body.appendChild(div);
          div.appendChild(video);
          video.srcObject = stream;
          await video.play();

          // Resize video to fit
          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

          await new Promise((resolve) => capture.onclick = resolve);

          const canvas = document.createElement('canvas');
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          canvas.getContext('2d').drawImage(video, 0, 0);
          stream.getTracks().forEach(track => track.stop());
          div.remove();

          return canvas.toDataURL('image/jpeg');
        }
        takePhoto();
    ''')

    display(js)
    data = eval_js("takePhoto()")
    binary = io.BytesIO(base64.b64decode(data.split(',')[1]))
    img = PIL.Image.open(binary)
    return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)

import base64
from tensorflow.keras.models import load_model
import numpy as np
import cv2

# Load model
model = load_model('asl_model.h5')

# Labels (update as per your model)
class_labels = list("ABCDEFGHIJKLMNOPQRSTUVWXYZ")

# Prediction helper
def predict_from_webcam_image():
    img = capture_image()
    cv2_imshow(img)  # Show captured image

    img_resized = cv2.resize(img, (64, 64)) / 255.0
    img_array = np.expand_dims(img_resized, axis=0)

    pred = model.predict(img_array)
    predicted_class = np.argmax(pred)
    print("Predicted Letter:", class_labels[predicted_class])
    print("Confidence:", pred[0][predicted_class])

predict_from_webcam_image()